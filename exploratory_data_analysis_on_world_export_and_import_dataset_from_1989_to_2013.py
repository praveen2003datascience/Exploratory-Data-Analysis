# -*- coding: utf-8 -*-
"""Exploratory Data Analysis on World Export and Import Dataset from 1989 to 2013.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qzPWXQlao4oFU-7nJV6tBQFXd2o7xjDZ
"""



# libraries
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import plotly.express as px
import ipywidgets as widgets
from IPython.display import display
import warnings
warnings.filterwarnings('ignore')
import seaborn as sns
import matplotlib.pyplot as plt
import mplcursors

data = pd.read_csv(r"C:\Users\Praveen T\Desktop\ass\34_years_world_export_import_dataset.csv")

data.head(10)

# number of columns present in the dataset.
len(data.columns)

# number of rows present in the dataset.
len(data)

# Descriptive statistics
data.describe()

"""# Data Preprocessing:"""

# finding number of missing values
data.isna().sum()

import pandas as pd


# Step 1: Replace missing values with mean for constant values
constant_cols = ['AHS Simple Average (%)', 'AHS Weighted Average (%)', 'AHS Total Tariff Lines',
                 'AHS Dutiable Tariff Lines Share (%)', 'AHS Duty Free Tariff Lines Share (%)',
                 'AHS Specific Tariff Lines Share (%)', 'AHS AVE Tariff Lines Share (%)',
                 'AHS MaxRate (%)', 'AHS MinRate (%)',
                 'MFN Simple Average (%)', 'MFN Weighted Average (%)', 'MFN Total Tariff Lines',
                 'MFN Dutiable Tariff Lines Share (%)', 'MFN Duty Free Tariff Lines Share (%)',
                 'MFN Specific Tariff Lines Share (%)', 'MFN AVE Tariff Lines Share (%)',
                 'MFN MaxRate (%)', 'MFN MinRate (%)']

# Replace missing values in constant columns with mean
data[constant_cols] = data[constant_cols].fillna(data[constant_cols].mean())

# Step 2: Replace missing values with mean for each country's total
# For each country, find the mean and replace missing values with it
for country in data['Partner Name'].unique():
    country_data = data[data['Partner Name'] == country]
    country_mean = country_data.mean()
    data.loc[data['Partner Name'] == country] = country_data.fillna(country_mean)

# Step 3: Replace missing values in specific columns with the mean value for each country's total
specific_cols = ['Revealed comparative advantage', 'World Growth (%)', 'Country Growth (%)']
for col in specific_cols:
    country_means = data.groupby('Partner Name')[col].transform('mean')
    data[col].fillna(country_means, inplace=True)

# Step 4: Replace remaining missing values with 0 or overall average
remaining_null_cols = ['Revealed comparative advantage', 'World Growth (%)', 'Country Growth (%)']
for col in remaining_null_cols:
    # Replace missing values with 0 if possible, otherwise with overall average
    if data[col].isnull().sum() > 0:
        data[col].fillna(0, inplace=True)
    else:
        data[col].fillna(data[col].mean(), inplace=True)

# After performing these steps, any remaining missing values should be replaced with 0 if possible, otherwise with the overall average.
# You can save the modified DataFrame to a new CSV file if needed
data.to_csv('filled_dataset.csv', index=False)  # Replace 'filled_dataset.csv' with desired filename

data.isna().sum()

"""# Outlier Detection"""

import numpy as np
from sklearn.neighbors import LocalOutlierFactor


numeric_columns = data.select_dtypes(include=np.number)

# Specify the number of neighbors
n_neighbors = 20

# Initialize the Local Outlier Factor (LOF) model
lof_model = LocalOutlierFactor(n_neighbors=n_neighbors, contamination='auto')

# Fit the model and predict outlier scores
outlier_scores = lof_model.fit_predict(numeric_columns)

# The 'outlier_scores' will contain 1 for inliers, -1 for outliers
# Convert -1 to True for easier filtering
outliers_mask = outlier_scores == -1

# Filter out the outliers
outliers = data[outliers_mask]

# Print or do further analysis with the outliers
print("Detected outliers:")
print(outliers)

cleaned_df = data.drop(outliers.index)

# Save the cleaned dataset to a new file
cleaned_df.to_csv('cleaned_dataset.csv', index=False)

# Print some information about the cleaning process
print(f"Original dataset shape: {data.shape}")
print(f"Number of outliers detected: {len(outliers)}")
print(f"Cleaned dataset shape: {cleaned_df.shape}")
print("Cleaned dataset saved as 'cleaned_dataset.csv'")

#After cleaning data from the dataset count
len(cleaned_df)

cleaned_df

"""# Exploratory Data Analysis (EDA)"""

# Import for Top 10 countries
import_by_country = data.groupby('Partner Name')['Import (US$ Thousand)'].sum().sort_values(ascending=False)
top_n = 11
import_by_country = import_by_country.head(top_n)
# Create bar chart
plt.figure(figsize=(10, 6))
import_by_country.plot(kind='bar', color='blue')
plt.xlabel('Country')
plt.ylabel('Total Import (US$ Thousand) - Top 10 Country')
plt.title('Total Import by Country')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Export for Top 10 countries

export_by_country = data.groupby('Partner Name')['Export (US$ Thousand)'].sum().sort_values(ascending=False)

# Extract top N countries for visualization, if needed
top_n = 11
export_by_country = export_by_country.head(top_n)

# Create bar chart
plt.figure(figsize=(10, 6))
export_by_country.plot(kind='bar', color='red')

# Add labels and title
plt.xlabel('Country')
plt.ylabel('Total Export (US$ Thousand) - Top 10 Country')
plt.title('Total Export by Country')

# Show plot
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import ipywidgets as widgets

def plot_export_import(country_name):
    country_data = data[data['Partner Name'] == country_name]
    country_data.set_index('Year', inplace=True)
    plt.figure(figsize=(10, 6))
    plt.bar(country_data.index, country_data['Export (US$ Thousand)'], color='skyblue', label='Export')
    plt.bar(country_data.index, country_data['Import (US$ Thousand)'],
            bottom=country_data['Export (US$ Thousand)'], color='orange', label='Import')
    plt.xlabel('Year')
    plt.ylabel('Value (US$ Thousand)')
    plt.title(f'Export and Import Values for {country_name}')
    plt.legend()
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# Create dropdown menu for selecting country
country_dropdown = widgets.Dropdown(
    options=data['Partner Name'].unique(),
    description='Country:'
)

# Create function to update plot when dropdown value changes
def update_plot(change):
    country_name = change.new
    plot_export_import(country_name)

# Attach update_plot function to the dropdown's observe method
country_dropdown.observe(update_plot, names='value')

# Display the dropdown
display(country_dropdown)

import matplotlib.pyplot as plt
import ipywidgets as widgets

def update_bar_chart(country_name, zoom_factor):
    country_data = data[data['Partner Name'] == country_name]
    if country_data.empty:
        print("No data found for the selected country.")
    else:
        # Plot bar chart for country growth over time
        plt.figure(figsize=(10, 6))
        plt.bar(country_data['Year'], country_data['Import (US$ Thousand)'], color='blue')

        # Add labels and title
        plt.xlabel('Year')
        plt.ylabel('Import (US$ Thousand)')
        plt.title(f'Import Values for {country_name}')

        # Apply zoom
        if zoom_factor > 0:
            min_import, max_import = min(country_data['Import (US$ Thousand)']), max(country_data['Import (US$ Thousand)'])
            plt.ylim(0, max_import * zoom_factor)

        # Show plot
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

# Create search bar for selecting country
country_dropdown = widgets.Dropdown(
    options=data['Partner Name'].unique(),
    description='Country:'
)

# Create zoom slider
zoom_slider = widgets.FloatSlider(
    value=1.0,
    min=0.1,
    max=2.0,
    step=0.1,
    description='Zoom Factor:'
)

# Display the dropdown, slider, and bar chart
widgets.interactive(update_bar_chart, country_name=country_dropdown, zoom_factor=zoom_slider)

def update_bar_chart(country_name, zoom_factor):
    country_data = data[data['Partner Name'] == country_name]
    if country_data.empty:
        print("No data found for the selected country.")
    else:
        # Plot bar chart for country growth over time
        plt.figure(figsize=(10, 6))
        plt.bar(country_data['Year'], country_data['Export (US$ Thousand)'], color='red')

        # Add labels and title
        plt.xlabel('Year')
        plt.ylabel('Export (US$ Thousand)')
        plt.title(f'Export Values for {country_name}')

        # Apply zoom
        if zoom_factor > 0:
            min_export, max_export = min(country_data['Export (US$ Thousand)']), max(country_data['Export (US$ Thousand)'])
            plt.ylim(0, max_export * zoom_factor)

        # Show data point values on hover
        mplcursors.cursor(hover=True)

        # Show plot
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.show()

# Create search bar for selecting country
country_dropdown = widgets.Dropdown(
    options=data['Partner Name'].unique(),
    description='Country:'
)

# Create zoom slider
zoom_slider = widgets.FloatSlider(
    value=1.0,
    min=0.1,
    max=2.0,
    step=0.1,
    description='Zoom Factor:'
)

# Display the dropdown, slider, and bar chart
widgets.interactive(update_bar_chart, country_name=country_dropdown, zoom_factor=zoom_slider)

import matplotlib.pyplot as plt
import ipywidgets as widgets

def update_pie_chart(country_name):
    country_data = data[data['Partner Name'] == country_name]
    if country_data.empty:
        print("No data found for the selected country.")
    else:
        total_import = country_data['Import (US$ Thousand)'].sum()
        total_export = country_data['Export (US$ Thousand)'].sum()

        labels=['Import','Export']
        values=[total_import,total_export]

        plt.figure(figsize=(8, 8))
        plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=140)
        plt.title(f"Overall Import and Export Total for {country_name}")
        plt.tight_layout()
        plt.show()

# Create search bar for selecting country
country_dropdown = widgets.Dropdown(
    options=data['Partner Name'].unique(),
    description='Country:'
)

# Display the dropdown and pie chart
widgets.interactive(update_pie_chart, country_name=country_dropdown)

import matplotlib.pyplot as plt
import ipywidgets as widgets

def update_line_chart(country_name, zoom_factor):
    country_data = data[data['Partner Name'] == country_name]
    if country_data.empty:
        print("No data found for the selected country.")
    else:
        # Plot line chart with markers for country growth over time
        plt.figure(figsize=(10, 6))
        plt.plot(country_data['Year'], country_data['Country Growth (%)'], marker='o', color='skyblue', linestyle='-')

        # Add labels and title
        plt.xlabel('Year')
        plt.ylabel('Country Growth (%)')
        plt.title(f'Country Growth over Time for {country_name}')

        # Apply zoom
        if zoom_factor > 0:
            min_year, max_year = min(country_data['Year']), max(country_data['Year'])
            min_growth, max_growth = min(country_data['Country Growth (%)']), max(country_data['Country Growth (%)'])
            plt.xlim(min_year - 0.05 * zoom_factor * (max_year - min_year), max_year + 0.05 * zoom_factor * (max_year - min_year))
            plt.ylim(min_growth - 0.05 * zoom_factor * (max_growth - min_growth), max_growth + 0.05 * zoom_factor * (max_growth - min_growth))

        # Show plot
        plt.xticks(rotation=45)
        plt.grid(True)  # Add grid lines for better readability
        plt.tight_layout()
        plt.show()

# Prompt the user to enter the country name and zoom factor
country_dropdown = widgets.Dropdown(
    options=data['Partner Name'].unique(),
    description='Country:'
)

zoom_slider = widgets.FloatSlider(
    value=1.0,
    min=0.1,
    max=2.0,
    step=0.1,
    description='Zoom Factor:'
)

# Display the dropdown, slider, and line chart
widgets.interactive(update_line_chart, country_name=country_dropdown, zoom_factor=zoom_slider)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import ipywidgets as widgets


# Your column names
column_names = ['Partner Name', 'Year', 'Export (US$ Thousand)', 'Import (US$ Thousand)',
                'Export Product Share (%)', 'Import Product Share (%)',
                'Revealed comparative advantage', 'World Growth (%)', 'Country Growth (%)',
                'AHS Simple Average (%)', 'AHS Weighted Average (%)', 'AHS Total Tariff Lines',
                'AHS Dutiable Tariff Lines Share (%)', 'AHS Duty Free Tariff Lines Share (%)',
                'AHS Specific Tariff Lines Share (%)', 'AHS AVE Tariff Lines Share (%)',
                'AHS MaxRate (%)', 'AHS MinRate (%)',
                'AHS SpecificDuty Imports (US$ Thousand)', 'AHS Dutiable Imports (US$ Thousand)',
                'AHS Duty Free Imports (US$ Thousand)', 'MFN Simple Average (%)', 'MFN Weighted Average (%)',
                'MFN Total Tariff Lines', 'MFN Dutiable Tariff Lines Share (%)', 'MFN Duty Free Tariff Lines Share (%)',
                'MFN Specific Tariff Lines Share (%)', 'MFN AVE Tariff Lines Share (%)',
                'MFN MaxRate (%)', 'MFN MinRate (%)',
                'MFN SpecificDuty Imports (US$ Thousand)', 'MFN Dutiable Imports (US$ Thousand)',
                'MFN Duty Free Imports (US$ Thousand)']

# Create a search bar
search_bar = widgets.Text(
    placeholder='Type country name...',
    description='Country:'
)

# Define a function to update the heatmap based on selected country
def update_heatmap(country_name):
    selected_data = data[data['Partner Name'] == country_name][column_names]
    if selected_data.empty:
        print("No data found for the selected country.")
    else:
        # Selecting only numeric columns for the heatmap
        numeric_data = selected_data.select_dtypes(include=['float64', 'int64'])

        # Calculating correlation matrix
        correlation_matrix = numeric_data.corr()

        # Plotting the heatmap
        plt.figure(figsize=(14, 10))
        sns.heatmap(correlation_matrix, annot=True, cmap='YlGnBu')
        plt.title(f'Correlation Heatmap for {country_name}')
        plt.show()

# Link the search bar to the function
widgets.interactive(update_heatmap, country_name=search_bar)

correlation_matrix = data.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='plasma', fmt=".2f", linewidths=0.5)
plt.title('Correlation Matrix of Numerical Features')
plt.show()

correlation_threshold = 0.8
highly_correlated_features = []

# Loop through columns of the correlation matrix
for i, column in enumerate(correlation_matrix.columns):
    for j in range(i):
        if abs(correlation_matrix.iloc[i, j]) > correlation_threshold:
            # Add the pair of highly correlated features to the list
            highly_correlated_features.append((column, correlation_matrix.columns[j]))

print("Features with high correlation:")
for feature_pair in highly_correlated_features:
    print(f"{feature_pair[0]} and {feature_pair[1]}: {correlation_matrix.loc[feature_pair[0], feature_pair[1]]:.2f}")

"""# Dimensionality Reduction Using PCA"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Separate features and target variable
X = data.drop(columns=['Country Growth (%)'])
y = data['Country Growth (%)']

# Identify numeric and categorical columns
numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns
categorical_cols = X.select_dtypes(include=['object']).columns

# Scale the numeric features
scaler = StandardScaler()
X_scaled = X.copy()
X_scaled[numeric_cols] = scaler.fit_transform(X_scaled[numeric_cols])

# Perform dimensionality reduction using PCA
pca = PCA(n_components=5)  # Adjust the number of components as needed
X_pca = pca.fit_transform(X_scaled[numeric_cols])

# Convert X_pca to a DataFrame
X_pca_df = pd.DataFrame(X_pca, columns=[f"PC_{i+1}" for i in range(X_pca.shape[1])])

# Return the dimensionality-reduced data
X_pca_df.head()

import matplotlib.pyplot as plt

# Extract PC_1 and PC_2 values
PC_1 = X_pca_df['PC_1']
PC_2 = X_pca_df['PC_2']

# Create a scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(PC_1, PC_2, alpha=0.5)
plt.title('Scatter Plot of PC_1 vs PC_2')
plt.xlabel('PC_1')
plt.ylabel('PC_2')
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# Extract PC_1 and PC_2 values
PC_2 = X_pca_df['PC_2']
PC_3 = X_pca_df['PC_3']

# Create a scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(PC_2, PC_3, alpha=0.5)
plt.title('Scatter Plot of PC_2 vs PC_3')
plt.xlabel('PC_2')
plt.ylabel('PC_3')
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# Extract PC_1 and PC_2 values
PC_3 = X_pca_df['PC_3']
PC_4 = X_pca_df['PC_4']

# Create a scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(PC_3, PC_4, alpha=0.5)
plt.title('Scatter Plot of PC_3 vs PC_4')
plt.xlabel('PC_3')
plt.ylabel('PC_4')
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# Extract PC_1 and PC_2 values
PC_4 = X_pca_df['PC_4']
PC_5 = X_pca_df['PC_5']

# Create a scatter plot
plt.figure(figsize=(8, 6))
plt.scatter(PC_4, PC_5, alpha=0.5)
plt.title('Scatter Plot of PC_4 vs PC_5')
plt.xlabel('PC_4')
plt.ylabel('PC_5')
plt.grid(True)
plt.show()

"""# Feature Selection:"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

numeric_df = data.select_dtypes(include=['float64', 'int64'])
X = numeric_df.drop(columns=['Country Growth (%)'])  # Drop the target variable if available
y = numeric_df['Country Growth (%)'] if 'Country Growth (%)' in numeric_df.columns else None

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 1. Correlation Analysis
# Calculate the correlation matrix
correlation_matrix = X_train.corr()

# Select features with high absolute correlation coefficients
high_corr_features = correlation_matrix[abs(correlation_matrix) > 0.5].stack().reset_index().rename(columns={0: 'correlation'})
high_corr_features = high_corr_features[high_corr_features['level_0'] != high_corr_features['level_1']]
high_corr_features = high_corr_features.drop_duplicates(subset='correlation')

# Print selected features
print("Features selected based on correlation analysis:")
print(high_corr_features)

rf = RandomForestRegressor()
rf.fit(X_train, y_train)

# Get feature importances
feature_importances = pd.DataFrame({'Feature': X_train.columns, 'Importance': rf.feature_importances_})
feature_importances = feature_importances.sort_values(by='Importance', ascending=False)

# Select top features based on importance scores
top_features = feature_importances.head(10)  # Select top 10 features (you can adjust this number)

# Print selected features
print("\nTop features selected based on feature importance:")
top_features

